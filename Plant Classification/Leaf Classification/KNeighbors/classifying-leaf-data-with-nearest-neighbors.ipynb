{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc95189f-97e9-bf0a-d5b0-7f197f3dc8db"
   },
   "source": [
    "# Nearest Neighbors\n",
    "In this notebook, I will create a simple nearest neighbors model to classify the leaves dataset as provided by Kaggle. I make use of euclidean distances, k nearest neighbors, log loss as a metric and cross validation.\n",
    "\n",
    "* **Proccessing Data**\n",
    "    * Loading Dada\n",
    "    * Extract features & labels\n",
    "    * Normalize Features\n",
    "    * Training & Validation Split\n",
    "* **Nearest Neighbors**\n",
    "    * Euclidean Distances\n",
    "    * K Nearest Neighbors\n",
    "    * Probability Dataframe\n",
    "    * Predictions\n",
    "    * Log Loss Metric\n",
    "    * Cross-Validation\n",
    "    * Probabilities Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3d613868-0116-c2c2-fb04-50d4e21537a0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4f9dd6f-0670-b164-33f8-b2f878234125"
   },
   "source": [
    "# Proccess Data\n",
    "## Loading Data\n",
    "First, the train and test data is loaded into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "901cce4e-d0bd-7564-c09a-19268c58bade"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152340</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "id                                                                            \n",
       "1             Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "2   Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625  0.025391   \n",
       "3    Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812  0.003906   \n",
       "5         Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859  0.021484   \n",
       "6      Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766  0.013672   \n",
       "8    Magnolia_Salicifolia  0.070312  0.093750  0.033203  0.001953  0.000000   \n",
       "\n",
       "     margin6   margin7  margin8   margin9    ...      texture55  texture56  \\\n",
       "id                                           ...                             \n",
       "1   0.009766  0.027344      0.0  0.001953    ...       0.007812   0.000000   \n",
       "2   0.001953  0.019531      0.0  0.000000    ...       0.000977   0.000000   \n",
       "3   0.005859  0.068359      0.0  0.000000    ...       0.154300   0.000000   \n",
       "5   0.019531  0.023438      0.0  0.013672    ...       0.000000   0.000977   \n",
       "6   0.015625  0.005859      0.0  0.000000    ...       0.096680   0.000000   \n",
       "8   0.152340  0.007812      0.0  0.003906    ...       0.145510   0.000000   \n",
       "\n",
       "    texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "id                                                                     \n",
       "1    0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "2    0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "3    0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "5    0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "6    0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "8    0.041992   0.000000   0.005859        0.0        0.0   0.000000   \n",
       "\n",
       "    texture63  texture64  \n",
       "id                        \n",
       "1    0.000000   0.025391  \n",
       "2    0.039062   0.022461  \n",
       "3    0.020508   0.002930  \n",
       "5    0.000000   0.047852  \n",
       "6    0.000000   0.031250  \n",
       "8    0.001953   0.013672  \n",
       "\n",
       "[6 rows x 193 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../input/train.csv', index_col=0)\n",
    "testData = pd.read_csv('../input/test.csv', index_col=0)\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5695232-d582-6d6d-b3c8-83d23917d2f2"
   },
   "source": [
    "## Extract features & labels\n",
    "We shuffle the data in this early stadium, to avoid index influence when splitting into training and validation sets. Next, the training labels and features are being separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "5b8f299a-b89c-a8cf-29cb-bc52f0a57361"
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)\n",
    "features = data[data.columns[1:193]]\n",
    "labels = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "43477e14-6519-e23c-9ddc-4b3ca526dc7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166020</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101560</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "id                                                                           \n",
       "562   0.035156  0.064453  0.011719  0.001953  0.000000  0.166020  0.007812   \n",
       "1482  0.003906  0.003906  0.076172  0.027344  0.025391  0.025391  0.031250   \n",
       "733   0.013672  0.009766  0.060547  0.044922  0.001953  0.025391  0.015625   \n",
       "270   0.023438  0.015625  0.021484  0.009766  0.000000  0.101560  0.029297   \n",
       "1198  0.009766  0.031250  0.003906  0.005859  0.005859  0.009766  0.054688   \n",
       "\n",
       "      margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "id                                   ...                                        \n",
       "562       0.0  0.009766  0.046875    ...       0.317380   0.000000   0.030273   \n",
       "1482      0.0  0.003906  0.021484    ...       0.000000   0.000000   0.002930   \n",
       "733       0.0  0.007812  0.033203    ...       0.000000   0.008789   0.000000   \n",
       "270       0.0  0.005859  0.044922    ...       0.007812   0.000000   0.058594   \n",
       "1198      0.0  0.000000  0.042969    ...       0.113280   0.000000   0.028320   \n",
       "\n",
       "      texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "id                                                                       \n",
       "562    0.000000   0.005859   0.000000        0.0   0.000000   0.019531   \n",
       "1482   0.010742   0.019531   0.000000        0.0   0.000000   0.000000   \n",
       "733    0.016602   0.000000   0.025391        0.0   0.171880   0.000000   \n",
       "270    0.000000   0.000000   0.000000        0.0   0.000000   0.053711   \n",
       "1198   0.000000   0.019531   0.000000        0.0   0.000977   0.000000   \n",
       "\n",
       "      texture64  \n",
       "id               \n",
       "562    0.019531  \n",
       "1482   0.008789  \n",
       "733    0.000000  \n",
       "270    0.046875  \n",
       "1198   0.005859  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1d6d741-d574-eff3-6066-789ffe7bcee9"
   },
   "source": [
    "## Normalize Features\n",
    "The training and testing features are being normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "91ba8691-377f-80f9-de97-0039f1d15a2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.042462</td>\n",
       "      <td>0.042504</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027110</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037720</td>\n",
       "      <td>0.020749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.058878</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.034685</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.038227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.027750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.027917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.046801</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021686</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.028308</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049849</td>\n",
       "      <td>0.035838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>0.058023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103731</td>\n",
       "      <td>0.049799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.066898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "id                                                                           \n",
       "562   0.042462  0.042504  0.009058  0.001690  0.000000  0.081488  0.009556   \n",
       "1482  0.004718  0.002576  0.058878  0.023667  0.034685  0.012463  0.038227   \n",
       "733   0.016513  0.006440  0.046801  0.038882  0.002668  0.012463  0.019114   \n",
       "270   0.028308  0.010304  0.016606  0.008453  0.000000  0.049849  0.035838   \n",
       "1198  0.011795  0.020608  0.003019  0.005071  0.008004  0.004793  0.066898   \n",
       "\n",
       "      margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "id                                   ...                                        \n",
       "562       0.0  0.027110  0.060545    ...       0.137929   0.000000   0.034176   \n",
       "1482      0.0  0.010843  0.027750    ...       0.000000   0.000000   0.003308   \n",
       "733       0.0  0.021686  0.042886    ...       0.000000   0.013999   0.000000   \n",
       "270       0.0  0.016264  0.058023    ...       0.003395   0.000000   0.066149   \n",
       "1198      0.0  0.000000  0.055500    ...       0.049230   0.000000   0.031971   \n",
       "\n",
       "      texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "id                                                                       \n",
       "562    0.000000   0.008375   0.000000        0.0   0.000000   0.037720   \n",
       "1482   0.012379   0.027917   0.000000        0.0   0.000000   0.000000   \n",
       "733    0.019132   0.000000   0.013072        0.0   0.124208   0.000000   \n",
       "270    0.000000   0.000000   0.000000        0.0   0.000000   0.103731   \n",
       "1198   0.000000   0.027917   0.000000        0.0   0.000706   0.000000   \n",
       "\n",
       "      texture64  \n",
       "id               \n",
       "562    0.020749  \n",
       "1482   0.009337  \n",
       "733    0.000000  \n",
       "270    0.049799  \n",
       "1198   0.006224  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features / np.linalg.norm(features, axis=0)\n",
    "testData = testData / np.linalg.norm(testData, axis=0)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42b3bc5e-ef25-3a24-5ad9-b6357f5d2021"
   },
   "source": [
    "## Training & Validation Split\n",
    "To test some later helper functions, we split the training data into a train and validation set. Later, we'll do this again via cross-validation. For now, we put aside one tenth for validation. As we shuffled already, we can just split via indeces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "310818d0-ddfe-7ba7-25fe-3d48ae6d2770"
   },
   "outputs": [],
   "source": [
    "trainFeatures = features.iloc[:891,:]\n",
    "validFeatures = features.iloc[891:,:]\n",
    "trainLabels =  labels.iloc[:891]\n",
    "validLabels = labels.iloc[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "29b96d8e-77e3-f6b9-758d-1b9b2b47f1b2"
   },
   "source": [
    "# Nearest Neighbors\n",
    "## Euclidean Distances\n",
    "Let's say we want to get the closest neighbor in the training set for the datapoint with index 1 in the validation set. We create a function to calculate all euclidean distances between this query on the one hand, and all training points on the other. Then, we take a look at the label of the training point with the lowest distance. The label turns out to be the same as the label of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "f9bb1153-263e-c509-bbae-9c73e86a1e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salix_Fragilis'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes distance(s) between a query and training point(s)\n",
    "def computeDistances(trainData, query):\n",
    "    distances = np.sqrt(np.sum((trainData - query)**2, axis=1))\n",
    "    return distances\n",
    "distances = computeDistances(trainFeatures, validFeatures.iloc[1,:])\n",
    "trainLabels.loc[distances.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "cf3b59d2-519a-19a2-2fb1-3cf4e77a4dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salix_Fragilis'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validLabels.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cde3cc91-ac4f-8020-1ea4-c8682ed76ab6"
   },
   "source": [
    "## K Nearest Neighbors\n",
    "Now, we would like a given number (k) of close neighbors, representing a probability distribution. All k nearest neighbors are equally weighted, each with a probability of 1/k. We create a function that, for a given query, returns a dictionary with the closest neighbors and their probabilities as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "47642074-1292-99ca-7fca-9765dfe50d6a"
   },
   "outputs": [],
   "source": [
    "def getNearestNeighbors(trainFeatures, trainLabels, query, k):\n",
    "    distances = computeDistances(trainFeatures, query)\n",
    "    lowestTen = distances.sort_values().head(k).index\n",
    "    results = dict()\n",
    "    for x in trainLabels[lowestTen]:\n",
    "        if x not in results:\n",
    "            results[x] = 1/float(k)\n",
    "        else:\n",
    "            results[x] += 1/float(k)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "2264e707-e528-c546-b9b3-e7968a826e33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acer_Rufinerve': 0.1,\n",
       " 'Betula_Pendula': 0.1,\n",
       " 'Pterocarya_Stenoptera': 0.1,\n",
       " 'Quercus_Coccifera': 0.1,\n",
       " 'Salix_Fragilis': 0.5,\n",
       " 'Tilia_Tomentosa': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNearestNeighbors(trainFeatures, trainLabels, validFeatures.iloc[1,:], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "624c97d8-2b18-1c4c-9b2f-b23e453ccf8e"
   },
   "source": [
    "So in this instance with k=10, each 0.1 acts as a 'vote' for that leaf class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "87527548-d305-e9f5-6fbe-d2a7e98df105"
   },
   "source": [
    "## Probability Dataframe\n",
    "The purpose of the following, is to generate dictionaries as above for all queries in a validation or test set, and to collect the probabilities in one dataframe. First, we store all the unique leaf classes in alphabetical order for this dataframe. We initiate this probability dataframe with all zeros. Then, we loop per query through the closest neighbors, adjusting the appropriate position in the probability dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "ebef5c10-266b-2793-7da1-2f0547d5b5fc"
   },
   "outputs": [],
   "source": [
    "def getProbabilities(trainFeatures, trainLabels, testFeatures, k):\n",
    "    leaves = np.unique(data.species.sort_values().values)\n",
    "    probabilities = pd.DataFrame(0, index=testFeatures.index, columns=leaves)\n",
    "    for index, query in zip(testFeatures.index, testFeatures.values):\n",
    "        for key, value in getNearestNeighbors(trainFeatures, trainLabels, query, k).items():\n",
    "            probabilities.loc[index, key] = value\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "435bd6ff-2c52-f2db-48a5-7e199cb193a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acer_Capillipes  Acer_Circinatum  Acer_Mono  Acer_Opalus  Acer_Palmatum  \\\n",
       "id                                                                              \n",
       "1347             0.00             0.00       0.02         0.04            0.0   \n",
       "1543             0.06             0.00       0.00         0.03            0.0   \n",
       "1206             0.00             0.00       0.06         0.00            0.0   \n",
       "1539             0.00             0.00       0.02         0.01            0.0   \n",
       "323              0.05             0.02       0.00         0.10            0.0   \n",
       "\n",
       "      Acer_Pictum  Acer_Platanoids  Acer_Rubrum  Acer_Rufinerve  \\\n",
       "id                                                                \n",
       "1347         0.00             0.00         0.00             0.0   \n",
       "1543         0.00             0.00         0.08             0.1   \n",
       "1206         0.01             0.00         0.00             0.0   \n",
       "1539         0.06             0.02         0.00             0.0   \n",
       "323          0.00             0.00         0.00             0.0   \n",
       "\n",
       "      Acer_Saccharinum       ...         Salix_Fragilis  Salix_Intergra  \\\n",
       "id                           ...                                          \n",
       "1347               0.0       ...                   0.00            0.07   \n",
       "1543               0.0       ...                   0.06            0.00   \n",
       "1206               0.0       ...                   0.00            0.00   \n",
       "1539               0.0       ...                   0.00            0.00   \n",
       "323                0.0       ...                   0.00            0.00   \n",
       "\n",
       "      Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  \\\n",
       "id                                                                      \n",
       "1347          0.0           0.00                0.00             0.00   \n",
       "1543          0.0           0.03                0.01             0.09   \n",
       "1206          0.0           0.00                0.00             0.00   \n",
       "1539          0.0           0.00                0.00             0.00   \n",
       "323           0.0           0.00                0.00             0.02   \n",
       "\n",
       "      Ulmus_Bergmanniana  Viburnum_Tinus  Viburnum_x_Rhytidophylloides  \\\n",
       "id                                                                       \n",
       "1347                0.00            0.06                           0.0   \n",
       "1543                0.07            0.00                           0.0   \n",
       "1206                0.00            0.06                           0.0   \n",
       "1539                0.00            0.03                           0.0   \n",
       "323                 0.00            0.04                           0.0   \n",
       "\n",
       "      Zelkova_Serrata  \n",
       "id                     \n",
       "1347             0.00  \n",
       "1543             0.00  \n",
       "1206             0.00  \n",
       "1539             0.00  \n",
       "323              0.05  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProbabilities(trainFeatures, trainLabels, validFeatures, 100).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b45b651d-ba97-bb71-76a1-0f20c5f59f30"
   },
   "source": [
    "Here we used a massive k-value, just to view some probabilities. Note that each row will sum to one, as it forms a probability distribution of the 99 leaf classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fce78f29-72dd-6676-6fc4-6017a3ba69a9"
   },
   "source": [
    "## Predictions\n",
    "Based on the probabilites, we are now interested in the leaf class with the highest probabilty, as this one would of course be our prediction if we had to make one. So we generate a probability dataframe, and return the leaf class with the highest probability per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "f2aae265-6797-9aab-1473-7982956a5962"
   },
   "outputs": [],
   "source": [
    "def getPredictions(trainFeatures, trainLabels, testFeatures, k):\n",
    "    testProbabilities = getProbabilities(trainFeatures, trainLabels, testFeatures, k)\n",
    "    return testProbabilities.idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "216f7f7e-6c24-88df-0d5e-9fcb5d70e934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1347          Ilex_Cornuta\n",
       "1543        Salix_Fragilis\n",
       "1206    Magnolia_Heptapeta\n",
       "1539      Quercus_Coccinea\n",
       "323      Quercus_Vulcanica\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validPredictions = getPredictions(trainFeatures, trainLabels, validFeatures, 10)\n",
    "validPredictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02b37a6b-e206-ff10-558e-d7a0c3fffabb"
   },
   "source": [
    "The above leaf classes are our predictions for the first five validation leaves, based on ten nearest neighbors. We'll see next that the log loss is a more interesting metric, but at the point, we could calculate the accuracy as well. We just check how many times the our prediction corresponds with the label, and divide this number by the total number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "62bff194-f8c5-fa4f-23e7-18a0ad0e19f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87878787878787878"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(validPredictions==validLabels)/float(len(validLabels))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8ba61d7-1351-5e5d-a10f-1e3b739ebf20"
   },
   "source": [
    "## Log Loss Metric\n",
    "The log loss is the metric uses at Kaggle, and accounts for (un)certainty. This is the formula, where L is the number of query leaves, C is the number of leaf classes, y is a binary value indicating whether leaf l actually belongs to class c (1 of so, 0 if not), and p is the probability that leaf l belongs to class c.\n",
    "\n",
    "$$\\text{logloss} = -\\frac{1}{L}\\sum_{l=1}^L\\sum_{c=1}^C{y_{lc}log(p_{lc})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1889646d-a53c-299a-3f8e-5219a9516dea"
   },
   "source": [
    "Here we implement the log loss function for a given training and validation set. Note that we substitute extreme values (0 and 1) in the probability matrix by very close values (0.0...01 and 0.99...) to make the log working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "7d2792b0-2baf-cba7-2a2c-3e5b16178aa7"
   },
   "outputs": [],
   "source": [
    "def getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, k):\n",
    "    leaves = np.unique(data.species.sort_values().values)\n",
    "    validProbabilities = getProbabilities(trainFeatures, trainLabels, validFeatures, k)\n",
    "    totalLoss = 0\n",
    "    for index, row in zip(validProbabilities.index, validProbabilities.values):\n",
    "        bools = np.zeros(99)\n",
    "        bools[np.where(leaves==validLabels.loc[index])] = 1\n",
    "        probs = np.zeros(len(row))\n",
    "        for i, x in enumerate(row):\n",
    "            probs[i] = np.log(max(min(x,1-10**-15),10**-15))\n",
    "        totalLoss += sum(bools*probs)\n",
    "    logLoss = totalLoss / -len(validProbabilities.values)\n",
    "    return logLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "0818e386-81fb-eac6-47a7-95280aa51a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1: 0.697753058483\n",
      "k = 2: 0.411889909292\n",
      "k = 3: 0.43831658322\n",
      "k = 4: 0.479388441625\n",
      "k = 5: 0.526839325465\n",
      "k = 6: 0.564864739188\n",
      "k = 7: 0.637120977118\n",
      "k = 8: 0.713813819554\n",
      "k = 9: 0.790526702809\n",
      "k = 10: 0.87372662513\n",
      "k = 11: 0.953210922618\n",
      "k = 12: 1.01973694005\n",
      "k = 13: 1.0911922646\n",
      "k = 14: 1.15210577561\n",
      "k = 15: 1.20463763074\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('k = ' + str(i+1) + ': ' + str(getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2954d28e-3b1f-76f6-b782-d7e2e0f77c0c"
   },
   "source": [
    "Here we calculated the logloss for 10 different values of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64a403ce-8a09-8d30-d4e6-899e65253806"
   },
   "source": [
    "## Cross-Validation\n",
    "The log loss as calculated above is quite heavily influenced by the choice of the test and validations split, though. By cross-validation, we reduce this variation. For a given number of folds, we run a logLoss on shifting validation sets. We then take the average of theses losses as our final logloss. The function takes the original features and labels as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "7dcb7b04-e25f-91dd-6fc3-a9b67ff33eab"
   },
   "outputs": [],
   "source": [
    "def crossValidation(features, labels, folds, k):\n",
    "    n = len(features)\n",
    "    totalLoss = 0\n",
    "    for i in range(folds):\n",
    "        start = int((n*i)/folds)\n",
    "        end = int((n*(i+1))/folds)\n",
    "        validFeatures = features.iloc[start:end,:]   \n",
    "        validLabels = labels.iloc[start:end]   \n",
    "        trainFeatures = features.iloc[0:start,:].append(features.iloc[end:n,:])        \n",
    "        trainLabels = labels.iloc[0:start].append(labels.iloc[end:n])        \n",
    "        totalLoss += getLogLoss(trainFeatures, trainLabels, validFeatures, validLabels, k)\n",
    "    averageLoss = totalLoss / folds\n",
    "    return averageLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "3cdfa8c4-790d-d16e-9dac-0583de0a3ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1: 0.83730367018\n",
      "k = 2: 0.566724011231\n",
      "k = 3: 0.500667153768\n",
      "k = 4: 0.50673449571\n",
      "k = 5: 0.45294835155\n",
      "k = 6: 0.466092417793\n",
      "k = 7: 0.453235023134\n",
      "k = 8: 0.482162802798\n",
      "k = 9: 0.555710547065\n",
      "k = 10: 0.631921638916\n",
      "k = 11: 0.704907654756\n",
      "k = 12: 0.76956438881\n",
      "k = 13: 0.835328481579\n",
      "k = 14: 0.897450940104\n",
      "k = 15: 0.924641531558\n"
     ]
    }
   ],
   "source": [
    "lossAll = np.zeros(15)\n",
    "for i in range(15):\n",
    "    lossAll[i] = crossValidation(features, labels, folds=10, k=i+1)\n",
    "    print('k = ' + str(i+1) + ': ' + str(lossAll[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5794b937-aeb4-1280-7364-f52825ef49be"
   },
   "source": [
    "Here we did the same as above, but with cross-validation (folding the data 10 times). The differenses are: (1) the values are much more stable and will be similar when rerun, (2) the calculation takes longer as, per k-value, the logLoss is calculated ten times. We can simply visualize these numbers to see that a k-value of about 5 results in the lowest logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "5d12af0d-61d8-a7d9-af41-2cc7972a147c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAF5CAYAAADQ2iM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11cc02c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 16),lossAll, 'r')\n",
    "plt.xlabel('# Nearest Neighbors = k')\n",
    "plt.ylabel('logLoss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f84eeeaf-283d-ea3a-232a-5a376a8cb44c"
   },
   "source": [
    "## Probabilities Testing Set\n",
    "Given the loglosses calculated above, we create a probability dataframe with k=5, based on all of the training data, for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "52f8a548-6436-9f2c-a938-e173d8247ab1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acer_Capillipes  Acer_Circinatum  Acer_Mono  Acer_Opalus  Acer_Palmatum  \\\n",
       "id                                                                            \n",
       "4               0.0              0.0        0.0          0.0            0.0   \n",
       "7               0.0              0.0        0.0          0.0            0.0   \n",
       "9               0.0              1.0        0.0          0.0            0.0   \n",
       "12              0.0              0.2        0.0          0.0            0.0   \n",
       "13              0.0              0.0        0.0          0.0            0.0   \n",
       "\n",
       "    Acer_Pictum  Acer_Platanoids  Acer_Rubrum  Acer_Rufinerve  \\\n",
       "id                                                              \n",
       "4           0.0              0.0          0.0             0.0   \n",
       "7           0.0              0.0          0.0             0.0   \n",
       "9           0.0              0.0          0.0             0.0   \n",
       "12          0.0              0.0          0.0             0.0   \n",
       "13          0.0              0.0          0.0             0.0   \n",
       "\n",
       "    Acer_Saccharinum       ...         Salix_Fragilis  Salix_Intergra  \\\n",
       "id                         ...                                          \n",
       "4                0.0       ...                    0.0             0.0   \n",
       "7                0.0       ...                    0.0             0.0   \n",
       "9                0.0       ...                    0.0             0.0   \n",
       "12               0.0       ...                    0.0             0.0   \n",
       "13               0.0       ...                    0.0             0.0   \n",
       "\n",
       "    Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  \\\n",
       "id                                                                    \n",
       "4           0.0            0.0                 0.0              0.0   \n",
       "7           0.0            0.0                 0.0              0.0   \n",
       "9           0.0            0.0                 0.0              0.0   \n",
       "12          0.0            0.0                 0.0              0.0   \n",
       "13          0.0            0.0                 0.0              0.0   \n",
       "\n",
       "    Ulmus_Bergmanniana  Viburnum_Tinus  Viburnum_x_Rhytidophylloides  \\\n",
       "id                                                                     \n",
       "4                  0.0             0.0                           0.0   \n",
       "7                  0.0             0.0                           0.0   \n",
       "9                  0.0             0.0                           0.0   \n",
       "12                 0.0             0.0                           0.0   \n",
       "13                 0.0             0.0                           0.0   \n",
       "\n",
       "    Zelkova_Serrata  \n",
       "id                   \n",
       "4               0.0  \n",
       "7               0.0  \n",
       "9               0.0  \n",
       "12              0.0  \n",
       "13              0.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = getProbabilities(features, labels, testData, 5)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
